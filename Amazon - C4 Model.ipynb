{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "!pip install contractions\n",
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import bigrams, trigrams\n",
    "import random\n",
    "import collections\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "from nltk.classify import MaxentClassifier\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "from nltk.classify.util import accuracy\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary of words and assigning True values to them\n",
    "def bag_of_words(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "# return a list of bigrams\n",
    "def bigramReturner (words):\n",
    "    word_list = words\n",
    "    bigramFeatureVector = []\n",
    "    for item in nltk.bigrams(word_list):\n",
    "        bigramFeatureVector.append(' '.join(item))\n",
    "    return bigramFeatureVector\n",
    "\n",
    "# return a list of trigrams\n",
    "def trigramReturner (words):\n",
    "    word_list = words\n",
    "    trigramFeatureVector = []\n",
    "    for item in nltk.trigrams(word_list):\n",
    "        trigramFeatureVector.append(' '.join(item))\n",
    "    return trigramFeatureVector\n",
    "\n",
    "# splits data 70/30\n",
    "def split_data(reviews_list, split=0.70):\n",
    "    \n",
    "    split_point = int(round(split*len(reviews_list),0))\n",
    "    split_point_2 = len(reviews_list) - split_point\n",
    "    \n",
    "    train, test = reviews_list[:split_point], reviews_list[-split_point_2:]\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rating_text\n",
    "del review_text\n",
    "del combined_ratings_reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "\n",
    "combined_ratings_reviews_list = []\n",
    "\n",
    "url_part_1 = \"https://www.amazon.com/Cellucor-Workout-Extract-Limeade-Servings/product-reviews/B00XFA544E/ref=cm_cr_arp_d_paging_btm_next_\"\n",
    "url_part_2 = \"?pageNumber=\"\n",
    "\n",
    "for a in range (1,61):\n",
    "    \n",
    "    url = url_part_1 + str(a) + url_part_2 + str(a)\n",
    "\n",
    "    browser.get(url)\n",
    "\n",
    "    # Give the page 3 sec to load\n",
    "    time.sleep(4)\n",
    "    \n",
    "    html = browser.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    containers = soup.find_all('div', {'data-hook':'review'})\n",
    "    \n",
    "    for f in range (0, len(containers)):\n",
    "        f_container = containers[f]\n",
    "        \n",
    "        title_text = f_container.find('a', {'data-hook':'review-title'}).find('span').text\n",
    "        \n",
    "        review_text = f_container.find('span', class_ = 'a-size-base review-text review-text-content').find('span').text\n",
    "        \n",
    "        rating_raw = int(f_container.find('span', class_ =\"a-icon-alt\").text[0])\n",
    "\n",
    "        rating_text = ''\n",
    "\n",
    "        if rating_raw == 5:\n",
    "            rating_text = 'pos'\n",
    "        elif rating_raw == 4:\n",
    "            rating_text = 'pos'\n",
    "        elif rating_raw == 3:\n",
    "            rating_text = 'neg'\n",
    "        elif rating_raw == 2:\n",
    "            rating_text = 'neg'\n",
    "        elif rating_raw == 1:\n",
    "            rating_text = 'neg'\n",
    "            \n",
    "        title_review_combined = str(title_text) + ' ' + str(review_text)\n",
    "            \n",
    "        combined_ratings_reviews_list.append([title_review_combined, rating_text])\n",
    "    \n",
    "browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(combined_ratings_reviews_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(combined_ratings_reviews_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = []\n",
    "bigrams = []\n",
    "trigrams = []\n",
    "ngrams = []\n",
    "\n",
    "for d in range(0,len(combined_ratings_reviews_list)):\n",
    "    record = combined_ratings_reviews_list[d]\n",
    "    \n",
    "    review = record[0]\n",
    "    rating = record[1]\n",
    "    \n",
    "    \n",
    "    lower_text = review.lower()\n",
    "    digit_free_text = re.sub(r'\\d+', '', lower_text)\n",
    "    words = word_tokenize(digit_free_text)\n",
    "    \n",
    "    expanded_contractions_tokens = []\n",
    "    \n",
    "    for a in words:\n",
    "        fixed_token = contractions.fix(a)\n",
    "        fixed_token_list = fixed_token.split()\n",
    "        for b in range(0, len(fixed_token_list)):\n",
    "            expanded_contractions_tokens.append(fixed_token_list[b])\n",
    "    \n",
    "    stripped_words = [word.strip(string.punctuation) for word in expanded_contractions_tokens]\n",
    "\n",
    "    further_stripped_words = [word.strip('…') for word in stripped_words]\n",
    "\n",
    "    split_words = []\n",
    "    \n",
    "    for word in further_stripped_words:\n",
    "        x = word.find('.')\n",
    "        if x == -1:\n",
    "            split_words.append(word)\n",
    "        else:\n",
    "            word1 = word[0:x]\n",
    "            word2 = word[x+1:len(word)]\n",
    "            split_words.append(word1)\n",
    "            split_words.append(word2)\n",
    "\n",
    "    further_split_words = []\n",
    "    \n",
    "    for word in split_words:\n",
    "        x = word.find('.')\n",
    "        if x == -1:\n",
    "            further_split_words.append(word)\n",
    "        else:\n",
    "            word1 = word[0:x]\n",
    "            word2 = word[x+1:len(word)]\n",
    "            further_split_words.append(word1)\n",
    "            further_split_words.append(word2)\n",
    "    \n",
    "    furthest_split_words = []\n",
    "    \n",
    "    for word in further_split_words:\n",
    "        x = word.find('/')\n",
    "        if x == -1:\n",
    "            furthest_split_words.append(word)\n",
    "        else:\n",
    "            word1 = word[0:x]\n",
    "            word2 = word[x+1:len(word)]\n",
    "            furthest_split_words.append(word1)\n",
    "            furthest_split_words.append(word2)\n",
    "  \n",
    "    punct_free_words = [word for word in furthest_split_words if word not in set(string.punctuation)]\n",
    "\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    \n",
    "    stop_free_words = [word for word in punct_free_words if word not in english_stops]\n",
    "\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_words = [wordnet_lemmatizer.lemmatize(word) for word in stop_free_words]\n",
    "    \n",
    "    characters_to_remove = ['...', \"'s\", '', 'le', 'u', '’', 'le', 'ca', 'st', 'nd', 'ft',\n",
    "                            '”', \"\", ' ', '  ' 'th', 'e', 'p', 'wo', 'wg', 'd', 'gon', 'na',\n",
    "                            '“', 'n', 'ê', 'pt', 'ot']\n",
    "    \n",
    "    review_list = [word for word in lemmatized_words if word not in characters_to_remove]\n",
    "    \n",
    "    bigrams_list = bigramReturner(review_list)\n",
    "\n",
    "    trigrams_list = trigramReturner(review_list)\n",
    "\n",
    "    ngrams_list = review_list + bigrams_list + trigrams_list\n",
    "\n",
    "    unigrams_feature_set = bag_of_words(review_list)\n",
    "\n",
    "    bigrams_feature_set = bag_of_words(bigrams_list)\n",
    "\n",
    "    trigrams_feature_set = bag_of_words(trigrams_list)\n",
    "\n",
    "    ngrams_feature_set = bag_of_words(ngrams_list)\n",
    "    \n",
    "    unigrams.append((unigrams_feature_set, rating))\n",
    "\n",
    "    bigrams.append((bigrams_feature_set, rating))\n",
    "\n",
    "    trigrams.append((trigrams_feature_set, rating))\n",
    "\n",
    "    ngrams.append((ngrams_feature_set, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_training_set, unigrams_testing_set = split_data(unigrams)\n",
    "\n",
    "bigrams_training_set, bigrams_testing_set = split_data(bigrams)\n",
    "\n",
    "trigrams_training_set, trigrams_testing_set = split_data(trigrams)\n",
    "\n",
    "ngrams_training_set, ngrams_testing_set = split_data(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a naive bayes classifier with the unigrams_training_set as input\n",
    "nb_unigrams_classifier = nltk.NaiveBayesClassifier.train(unigrams_training_set)\n",
    "\n",
    "# calculates the accuracy of the unigrams naive bayes classifier\n",
    "# as well as the precision, recall, and f-measure of both the \n",
    "# positive and negative classes\n",
    "nb_unigrams_refsets = collections.defaultdict(set)\n",
    "nb_unigrams_testsets = collections.defaultdict(set)\n",
    "nb_unigrams_labels = []\n",
    "nb_unigrams_tests = []\n",
    " \n",
    "for i, (feats, label) in enumerate(unigrams_testing_set):\n",
    "    nb_unigrams_refsets[label].add(i)\n",
    "    nb_unigrams_observed = nb_unigrams_classifier.classify(feats)\n",
    "    nb_unigrams_testsets[nb_unigrams_observed].add(i)\n",
    "    nb_unigrams_labels.append(label)\n",
    "    nb_unigrams_tests.append(nb_unigrams_observed)\n",
    "    \n",
    "nb_unigrams_accuracy = round(nltk.classify.accuracy(nb_unigrams_classifier, unigrams_testing_set),4)\n",
    "\n",
    "nb_unigrams_pos_prec = round(precision(nb_unigrams_refsets['pos'], nb_unigrams_testsets['pos']),4)\n",
    "nb_unigrams_pos_rec = round(recall(nb_unigrams_refsets['pos'], nb_unigrams_testsets['pos']),4)\n",
    "nb_unigrams_pos_f_measure = round(f_measure(nb_unigrams_refsets['pos'], nb_unigrams_testsets['pos']),4)\n",
    "\n",
    "nb_unigrams_neg_prec = round(precision(nb_unigrams_refsets['neg'], nb_unigrams_testsets['neg']),4)\n",
    "nb_unigrams_neg_rec = round(recall(nb_unigrams_refsets['neg'], nb_unigrams_testsets['neg']),4)\n",
    "nb_unigrams_neg_f_measure = round(f_measure(nb_unigrams_refsets['neg'], nb_unigrams_testsets['neg']),4)\n",
    "\n",
    "\n",
    "\n",
    "# creates a naive bayes classifier with the bigrams_training_set as input\n",
    "nb_bigrams_classifier = nltk.NaiveBayesClassifier.train(bigrams_training_set)\n",
    "\n",
    "\n",
    "# calculates the accuracy of the bigrams naive bayes classifier\n",
    "# as well as the precision, recall, and f-measure of both the \n",
    "# positive and negative classes\n",
    "nb_bigrams_refsets = collections.defaultdict(set)\n",
    "nb_bigrams_testsets = collections.defaultdict(set)\n",
    "nb_bigrams_labels = []\n",
    "nb_bigrams_tests = []\n",
    " \n",
    "for i, (feats, label) in enumerate(bigrams_testing_set):\n",
    "    nb_bigrams_refsets[label].add(i)\n",
    "    nb_bigrams_observed = nb_bigrams_classifier.classify(feats)\n",
    "    nb_bigrams_testsets[nb_bigrams_observed].add(i)\n",
    "    nb_bigrams_labels.append(label)\n",
    "    nb_bigrams_tests.append(nb_bigrams_observed)\n",
    "\n",
    "\n",
    "nb_bigrams_accuracy = round(nltk.classify.accuracy(nb_bigrams_classifier, bigrams_testing_set),4)\n",
    "\n",
    "nb_bigrams_pos_prec = round(precision(nb_bigrams_refsets['pos'], nb_bigrams_testsets['pos']),4)\n",
    "nb_bigrams_pos_rec = round(recall(nb_bigrams_refsets['pos'], nb_bigrams_testsets['pos']),4)\n",
    "nb_bigrams_pos_f_measure = round(f_measure(nb_bigrams_refsets['pos'], nb_bigrams_testsets['pos']),4)\n",
    "\n",
    "nb_bigrams_neg_prec = round(precision(nb_bigrams_refsets['neg'], nb_bigrams_testsets['neg']),4)\n",
    "nb_bigrams_neg_rec = round(recall(nb_bigrams_refsets['neg'], nb_bigrams_testsets['neg']),4)\n",
    "nb_bigrams_neg_f_measure = round(f_measure(nb_bigrams_refsets['neg'], nb_bigrams_testsets['neg']),4)\n",
    "\n",
    "\n",
    "# creates a naive bayes classifier with the trigrams_training_set as input\n",
    "nb_trigrams_classifier = nltk.NaiveBayesClassifier.train(trigrams_training_set)\n",
    "\n",
    "\n",
    "# calculates the accuracy of the trigrams naive bayes classifier\n",
    "# as well as the precision, recall, and f-measure of both the \n",
    "# positive and negative classes\n",
    "nb_trigrams_refsets = collections.defaultdict(set)\n",
    "nb_trigrams_testsets = collections.defaultdict(set)\n",
    "nb_trigrams_labels = []\n",
    "nb_trigrams_tests = []\n",
    " \n",
    "for i, (feats, label) in enumerate(trigrams_testing_set):\n",
    "    nb_trigrams_refsets[label].add(i)\n",
    "    nb_trigrams_observed = nb_trigrams_classifier.classify(feats)\n",
    "    nb_trigrams_testsets[nb_trigrams_observed].add(i)\n",
    "    nb_trigrams_labels.append(label)\n",
    "    nb_trigrams_tests.append(nb_trigrams_observed)\n",
    "\n",
    "\n",
    "nb_trigrams_accuracy = round(nltk.classify.accuracy(nb_trigrams_classifier, trigrams_testing_set),4)\n",
    "\n",
    "nb_trigrams_pos_prec = round(precision(nb_trigrams_refsets['pos'], nb_trigrams_testsets['pos']),4)\n",
    "nb_trigrams_pos_rec = round(recall(nb_trigrams_refsets['pos'], nb_trigrams_testsets['pos']),4)\n",
    "nb_trigrams_pos_f_measure = round(f_measure(nb_trigrams_refsets['pos'], nb_trigrams_testsets['pos']),4)\n",
    "\n",
    "nb_trigrams_neg_prec = precision(nb_trigrams_refsets['neg'], nb_trigrams_testsets['neg'])\n",
    "nb_trigrams_neg_rec = round(recall(nb_trigrams_refsets['neg'], nb_trigrams_testsets['neg']),4)\n",
    "nb_trigrams_neg_f_measure = f_measure(nb_trigrams_refsets['neg'], nb_trigrams_testsets['neg'])\n",
    "\n",
    "\n",
    "# creates a naive bayes classifier with the ngrams_training_set as input\n",
    "nb_ngrams_classifier = nltk.NaiveBayesClassifier.train(ngrams_training_set)\n",
    "\n",
    "\n",
    "# calculates the accuracy of the ngrams naive bayes classifier\n",
    "# as well as the precision, recall, and f-measure of both the \n",
    "# positive and negative classes\n",
    "nb_ngrams_refsets = collections.defaultdict(set)\n",
    "nb_ngrams_testsets = collections.defaultdict(set)\n",
    "nb_ngrams_labels = []\n",
    "nb_ngrams_tests = []\n",
    " \n",
    "for i, (feats, label) in enumerate(ngrams_testing_set):\n",
    "    nb_ngrams_refsets[label].add(i)\n",
    "    nb_ngrams_observed = nb_ngrams_classifier.classify(feats)\n",
    "    nb_ngrams_testsets[nb_ngrams_observed].add(i)\n",
    "    nb_ngrams_labels.append(label)\n",
    "    nb_ngrams_tests.append(nb_ngrams_observed)\n",
    "\n",
    "nb_ngrams_accuracy = round(nltk.classify.accuracy(nb_ngrams_classifier, ngrams_testing_set),4)\n",
    "\n",
    "nb_ngrams_pos_prec = round(precision(nb_ngrams_refsets['pos'], nb_ngrams_testsets['pos']),4)\n",
    "nb_ngrams_pos_rec = round(recall(nb_ngrams_refsets['pos'], nb_ngrams_testsets['pos']),4)\n",
    "nb_ngrams_pos_f_measure = round(f_measure(nb_ngrams_refsets['pos'], nb_ngrams_testsets['pos']),4)\n",
    "\n",
    "nb_ngrams_neg_prec = round(precision(nb_ngrams_refsets['neg'], nb_ngrams_testsets['neg']),4)\n",
    "nb_ngrams_neg_rec = round(recall(nb_ngrams_refsets['neg'], nb_ngrams_testsets['neg']),4)\n",
    "nb_ngrams_neg_f_measure = round(f_measure(nb_ngrams_refsets['neg'], nb_ngrams_testsets['neg']),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"Features\", \"Metrics\", \"Naive Bayes\"]\n",
    "\n",
    "x.add_row([\" \", \"Accuracy\", nb_unigrams_accuracy])\n",
    "x.add_row([\" \", \"Pos Precision\", nb_unigrams_pos_prec])\n",
    "x.add_row([\" \", \"Pos Recall\", nb_unigrams_pos_rec])\n",
    "x.add_row([\"Unigrams\", \"Pos F-Measure\", nb_unigrams_pos_f_measure])\n",
    "x.add_row([\" \", \"Neg Precision\", nb_unigrams_neg_prec])\n",
    "x.add_row([\" \", \"Neg Recall\", nb_unigrams_neg_rec])\n",
    "x.add_row([\"________\", \"Neg F-Measure\", nb_unigrams_neg_f_measure])\n",
    "\n",
    "x.add_row([\" \", \"Accuracy\", nb_bigrams_accuracy])\n",
    "x.add_row([\" \", \"Pos Precision\", nb_bigrams_pos_prec])\n",
    "x.add_row([\" \", \"Pos Recall\", nb_bigrams_pos_rec])\n",
    "x.add_row([\"Bigrams\", \"Pos F-Measure\", nb_bigrams_pos_f_measure])\n",
    "x.add_row([\" \", \"Neg Precision\", nb_bigrams_neg_prec])\n",
    "x.add_row([\" \", \"Neg Recall\", nb_bigrams_neg_rec])\n",
    "x.add_row([\"________\", \"Neg F-Measure\", nb_bigrams_neg_f_measure])\n",
    "\n",
    "x.add_row([\" \", \"Accuracy\", nb_trigrams_accuracy])\n",
    "x.add_row([\" \", \"Pos Precision\", nb_trigrams_pos_prec])\n",
    "x.add_row([\" \", \"Pos Recall\", nb_trigrams_pos_rec])\n",
    "x.add_row([\"Trigrams\", \"Pos F-Measure\", nb_trigrams_pos_f_measure])\n",
    "x.add_row([\" \", \"Neg Precision\", nb_trigrams_neg_prec])\n",
    "x.add_row([\" \", \"Neg Recall\", nb_trigrams_neg_rec])\n",
    "x.add_row([\"________\", \"Neg F-Measure\", nb_trigrams_neg_f_measure])\n",
    "\n",
    "x.add_row([\" \", \"Accuracy\", nb_ngrams_accuracy])\n",
    "x.add_row([\" \", \"Pos Precision\", nb_ngrams_pos_prec])\n",
    "x.add_row([\" \", \"Pos Recall\", nb_ngrams_pos_rec])\n",
    "x.add_row([\"N-grams\", \"Pos F-Measure\", nb_ngrams_pos_f_measure])\n",
    "x.add_row([\" \", \"Neg Precision\", nb_ngrams_neg_prec])\n",
    "x.add_row([\" \", \"Neg Recall\", nb_ngrams_neg_rec])\n",
    "x.add_row([\" \", \"Neg F-Measure\", nb_ngrams_neg_f_measure])\n",
    "\n",
    "x.align[\"Metrics\"] = \"l\"\n",
    "x.align[\"Naive Bayes\"] = \"l\"\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_unigrams_classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bigrams_classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_trigrams_classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_ngrams_classifier.show_most_informative_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
